{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgNOZxk1aS41VSzKS+CD4r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deep-diver/auto-paper-analysis/blob/main/notebooks/analyze_arxiv_pdf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "KV4QkPCAAwmz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai\n",
        "!pip install pypdf2\n",
        "!pip install fitz\n",
        "!pip install pymupdf"
      ],
      "metadata": {
        "id": "Jpxsv3SEs4ET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VEq5clsosz35"
      },
      "outputs": [],
      "source": [
        "GEMINI_API_KEY=\"...\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download_pdf_from_arxiv(arxiv_id):\n",
        "  url = f'http://export.arxiv.org/pdf/{arxiv_id}'\n",
        "  response = requests.get(url)\n",
        "  if response.status_code == 200:\n",
        "    return response.content\n",
        "  else:\n",
        "    raise Exception(f\"Failed to download pdf for arXiv id {arxiv_id}\")\n",
        "\n",
        "# Example usage\n",
        "arxiv_id = \"2306.00001\"\n",
        "pdf_content = download_pdf_from_arxiv(arxiv_id)\n",
        "\n",
        "# Save the pdf content to a file\n",
        "with open(f\"{arxiv_id}.pdf\", \"wb\") as f:\n",
        "  f.write(pdf_content)\n"
      ],
      "metadata": {
        "id": "g9Ima2kQtLPJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import PyPDF2\n",
        "\n",
        "def extract_text_and_figures(pdf_path):\n",
        "    \"\"\"\n",
        "    Extracts text and figures from a PDF file.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): The path to the PDF file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing two lists:\n",
        "            * A list of extracted text blocks.\n",
        "            * A list of extracted figures (as bytes).\n",
        "    \"\"\"\n",
        "\n",
        "    texts = []\n",
        "    figures = []\n",
        "\n",
        "    # Open the PDF using PyMuPDF (fitz) for image extraction\n",
        "    doc = fitz.open(pdf_path)\n",
        "    for page_num, page in enumerate(doc):\n",
        "        text = page.get_text(\"text\")  # Extract text as plain text\n",
        "        texts.append(text)\n",
        "\n",
        "        # Process images on the page\n",
        "        image_list = page.get_images()\n",
        "        for image_index, img in enumerate(image_list):\n",
        "            xref = img[0]  # Image XREF\n",
        "            pix = fitz.Pixmap(doc, xref)  # Create Pixmap image\n",
        "\n",
        "            # Save image in desired format (here, PNG)\n",
        "            if pix.n < 5:  # Grayscale or RGB\n",
        "                img_bytes = pix.tobytes(\"png\")\n",
        "            else:  # CMYK: Convert to RGB first\n",
        "                pix = fitz.Pixmap(fitz.csRGB, pix)\n",
        "                img_bytes = pix.tobytes(\"png\")\n",
        "\n",
        "            figures.append(img_bytes)\n",
        "\n",
        "    # Extract additional text using PyPDF2 (in case fitz didn't get everything)\n",
        "    with open(pdf_path, 'rb') as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text = page.extract_text()\n",
        "            texts.append(text)\n",
        "\n",
        "    return texts, figures\n"
      ],
      "metadata": {
        "id": "wci-rQVXtvHF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts, figures = extract_text_and_figures(f'{arxiv_id}.pdf')"
      ],
      "metadata": {
        "id": "m9FQwxPyufzQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "hUovrG-5uwbS",
        "outputId": "709634d9-d777-4af9-cbcf-ff51c990e50d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This paper has been accepted for publication at the\\nIEEE Conference on Artiﬁcial Intelligence Circuits and Systems (AICAS), Hangzhou, 2023.\\n©2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future\\nmedia, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or\\nredistribution to servers or lists, or reuse of any copyrighted component of this work in other works.\\nTinyissimoYOLO: A Quantized, Low-Memory\\nFootprint, TinyML Object Detection Network for\\nLow Power Microcontrollers\\nJulian Moosmann, Marco Giordano, Christian Vogt, Michele Magno\\nCenter for Project Based Learning - ETH Z¨urich\\njulian.moosmann, marco.giordano, christian.vogt, michele.magno@pbl.ee.ethz.ch\\nAbstract—This paper introduces a highly ﬂexible, quantized,\\nmemory-efﬁcient, and ultra-lightweight object detection network,\\ncalled TinyissimoYOLO. It aims to enable object detection on\\nmicrocontrollers in the power domain of milliwatts, with less\\nthan 0.5 MB memory available for storing convolutional neural\\nnetwork (CNN) weights. The proposed quantized network archi-\\ntecture with 422 k parameters, enables real-time object detection\\non embedded microcontrollers, and it has been evaluated to\\nexploit CNN accelerators. In particular, the proposed network has\\nbeen deployed on the MAX78000 microcontroller achieving high\\nframe-rate of up to 180 fps and an ultra-low energy consumption\\nof only 196 µJ per inference with an inference efﬁciency of more\\nthan 106 MAC/Cycle. TinyissimoYOLO can be trained for any\\nmulti-object detection. However, considering the small network\\nsize, adding object detection classes will increase the size and\\nmemory consumption of the network, thus object detection\\nwith up to 3 classes is demonstrated. Furthermore, the net-\\nwork is trained using quantization-aware training and deployed\\nwith 8-bit quantization on different microcontrollers, such as\\nSTM32H7A3, STM32L4R9, Apollo4b and on the MAX78000’s\\nCNN accelerator. Performance evaluations are presented in this\\npaper.\\nIndex Terms—YOLO, ML, computer vision, object detection,\\nCNN accelerator, microcontroller, quantization, quantization-\\naware training\\nI. INTRODUCTION\\nObject detection on edge devices such as microcontroller\\nunits (µCs) have the capability of reducing detection latency\\nand increasing the overall energy efﬁciency by running on-\\ndevice network inferences [1], [2]. In addition, the sensitive\\ntransmission of sensor data is reduced or substituted, reducing\\nprivacy issues to a minimum. Furthermore, emerging dedicated\\nhardware accelerators for machine learning (ML) models are\\nenabling edge processing and edge artiﬁcial intelligence (AI)\\nreducing the energy consumption for inference and enabling\\nreal-time on-board processing on resource-constrained micro-\\ncontrollers [3]. On such constrained devices, computational\\npower is signiﬁcantly reduced and does not allow for the\\ndeployment of classical object detection deep neural networks\\n(DNNs) such as you only look once (YOLO) [4], region-based\\nconvolutional neural networks (R-CNNs) [5] or single shot\\ndetectors (SSDs) [6] because their memory requirements are\\nsigniﬁcantly exceeding the available memory of few kilobytes\\ntypically available in such devices. However, their fundamental\\nThe authors would like to thank armasuisse Science & Technology for\\nfunding this research.\\nideas are of importance for designing new DNNs, especially\\nfor the emerging ﬁeld of edge AI.\\nIn fact, to keep the power consumption in the order of a few\\nmilliwatts, the computational power on µCs is signiﬁcantly\\nlower compared to CPUs and GPUs. Thus, object detection\\nnetworks need to be carefully designed and optimized for\\nsuch tiny devices in particular to achieve a small memory\\nfootprint and a high number of operations processed per cycle\\n[7]. To overcome the memory constraints, several different\\nmethods have been recently reported in literature, such as\\npruning [8], [9], quantization [10], [11], new frameworks\\ndeveloped for memory efﬁcient inference [12], patch-based\\ninference scheduling [13] or neural architecture searches in-\\ncluding search spaces specialized for memory-constrained\\ndevices [14], [15]. These techniques are used to reduce the\\nmemory and complexity of existing state-of-the-art networks\\nto deploy on a tiny device while keeping the original network’s\\nstructure and still achieving similar inference accuracy while\\nperformance (especially inference speed) is often neglected\\n[16]. Among other techniques, quantization is one of the\\nmost promising and popular, as it reduces both the memory\\nrequirements and increases the number of operations per\\nsecond that µCs can perform. Li et al. (2019) [17] have\\nshown that quantizing an object detection network to 4-bit,\\nthey achieve state-of-the-art prediction accuracy with a mean\\naverage precision (mAP) loss of only 2 % to 5 % compared\\nto its full precision counterpart while having 8x less memory\\noccupation.\\nTo the best of our knowledge, there is still no previous work\\nthat adopts those techniques to achieve a generalized object\\ndetection network, ready for deployment on edge devices and\\nµCs with less than 0.5 MB of weight memory, that are able\\nto achieve similar accuracy performance of larger networks.\\nThis paper proposes a quantized and highly accurate object\\ndetection convolutional neural network (CNN) based on the\\narchitecture of YOLO [4] suitable for edge processors with\\nlimited memory and computational resources. The proposed\\nnetwork is composed of quantized convolutional layers with\\n3x3 kernels and a fully connected layer at the output. It is\\ndesigned for having a low memory footprint of less than\\n0.5 MB. The proposed network is trained and evaluated on\\nthe WiderFace dataset [18]. Furthermore, to showcase multi-\\nobject detection capability, while keeping the network small,\\narXiv:2306.00001v2  [cs.CV]  12 Jul 2023\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(figures))\n",
        "print(type(figures[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W06HEk3AwzJa",
        "outputId": "23cd35cf-f99d-4fff-cd61-cc829f7b828c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "<class 'bytes'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "img = Image.open(io.BytesIO(figures[0]))\n",
        "display(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "O-LbjMwEw7mM",
        "outputId": "10f12631-ae5b-49d1-ecd6-32c32354bb30"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=1630x538>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def determine_model_name(given_image=None):\n",
        "  if given_image is None:\n",
        "    return \"gemini-pro\"\n",
        "  else:\n",
        "    return \"gemini-pro-vision\"\n",
        "\n",
        "def construct_image_part(given_image):\n",
        "  return {\n",
        "    \"mime_type\": \"image/jpeg\",\n",
        "    \"data\": given_image\n",
        "  }\n",
        "\n",
        "def call_gemini(prompt=\"\", API_KEY=None, given_text=None, given_image=None, generation_config=None, safety_settings=None):\n",
        "  import google.generativeai as genai\n",
        "  genai.configure(api_key=API_KEY)\n",
        "\n",
        "  if generation_config is None:\n",
        "    generation_config = {\n",
        "      \"temperature\": 0.4,\n",
        "      \"top_p\": 1,\n",
        "      \"top_k\": 32,\n",
        "      \"max_output_tokens\": 8192,\n",
        "    }\n",
        "\n",
        "  if safety_settings is None:\n",
        "    safety_settings = [\n",
        "      {\n",
        "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "        \"threshold\": \"BLOCK_ONLY_HIGH\"\n",
        "      },\n",
        "      {\n",
        "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        \"threshold\": \"BLOCK_ONLY_HIGH\"\n",
        "      },\n",
        "      {\n",
        "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "        \"threshold\": \"BLOCK_ONLY_HIGH\"\n",
        "      },\n",
        "      {\n",
        "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        \"threshold\": \"BLOCK_ONLY_HIGH\"\n",
        "      },\n",
        "    ]\n",
        "\n",
        "  model_name = determine_model_name(given_image)\n",
        "  model = genai.GenerativeModel(model_name=model_name,\n",
        "                                generation_config=generation_config,\n",
        "                                safety_settings=safety_settings)\n",
        "\n",
        "  USER_PROMPT = f\"\"\"\n",
        "  {prompt}\n",
        "  ------------------------------------------------\n",
        "  {given_text}\n",
        "  \"\"\"\n",
        "  prompt_parts = [USER_PROMPT]\n",
        "  if given_image is not None:\n",
        "    prompt_parts.append(construct_image_part(given_image))\n",
        "\n",
        "  response = model.generate_content(prompt_parts)\n",
        "  return response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "aZlduBW44Uil",
        "outputId": "ab5a7578-04f2-4c5e-fd46-41330d0da9b0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text =' '.join(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mh0ohRYSYJBb",
        "outputId": "adb1cb12-5940-488c-fca9-f9be60992cec"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_json = call_gemini(\n",
        "    prompt='Below is an academic paper extracted from a PDF file. '\n",
        "           'Come up with 10 questions ranging from basic to expert levels along with summarization. '\n",
        "           'Give me your response by filling in the following JSON. '\n",
        "           '{\"title\": text, \"summary\": text, \"qa\": [{\"q\": text, \"a\": text}, ...]}',\n",
        "    given_text=text,\n",
        "    API_KEY=GEMINI_API_KEY\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "U11PgP2yyFcD",
        "outputId": "5c142180-13b5-4adf-d75f-15651ceb29ac"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "7k4KGMGX9Zps",
        "outputId": "7bca51a1-9b73-4e0c-c9a2-1f9344d6d283"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n \"title\": \"TinyissimoYOLO: A Quantized, Low-Memory Footprint, TinyML Object Detection Network for Low Power Microcontrollers\",\\n \"summary\": \"This paper introduces TinyissimoYOLO, a quantized, memory-efficient, and ultra-lightweight object detection network suitable for edge processors with limited memory and computational resources. The proposed network is composed of quantized convolutional layers with 3x3 kernels and a fully connected layer at the output. It is designed to have a low memory footprint of less than 0.5 MB. The proposed network is trained and evaluated on the WiderFace dataset and a sub-set of the PascalVOC dataset. Furthermore, the network is deployed quantized and memory-efficient on different microcontrollers, such as the STM32H7A3 and STM32L4R9 from STMicroelectronics, Ambiq\\\\u2019s Apollo4b and on a novel microcontroller, MAX78000 from Analog Devices, which has a built-in CNN accelerator. The performance of the different architectures is compared and it is shown, how the MAX78000 outperforms the other microcontrollers. Furthermore, this paper investigates the effect of mAP against relative object size dimensions within images.\",\\n \"qa\": [\\n  {\\n   \"q\": \"What is the main contribution of this paper?\",\\n   \"a\": \"The main contribution of this paper is the introduction of TinyissimoYOLO, a quantized, memory-efficient, and ultra-lightweight object detection network suitable for edge processors with limited memory and computational resources.\"\\n  },\\n  {\\n   \"q\": \"What are the key design decisions of the TinyissimoYOLO network?\",\\n   \"a\": \"The key design decisions of the TinyissimoYOLO network encompass the following 4 points:\\\\n\\\\n* input image size,\\\\n* hidden convolutional layers,\\\\n* fully connected linear layer before the output layer,\\\\n* output layer size.\"\\n  },\\n  {\\n   \"q\": \"How is the TinyissimoYOLO network trained and evaluated?\",\\n   \"a\": \"The TinyissimoYOLO network is trained and evaluated on the WiderFace dataset and a sub-set of the PascalVOC dataset.\"\\n  },\\n  {\\n   \"q\": \"On which microcontrollers is the TinyissimoYOLO network deployed?\",\\n   \"a\": \"The TinyissimoYOLO network is deployed quantized and memory-efficient on different microcontrollers, such as the STM32H7A3 and STM32L4R9 from STMicroelectronics, Ambiq\\\\u2019s Apollo4b and on a novel microcontroller, MAX78000 from Analog Devices, which has a built-in CNN accelerator.\"\\n  },\\n  {\\n   \"q\": \"How does the MAX78000 microcontroller compare to the other microcontrollers in terms of performance?\",\\n   \"a\": \"The MAX78000 microcontroller outperforms the other microcontrollers in terms of latency, inference efficiency and energy per inference.\"\\n  },\\n  {\\n   \"q\": \"What is the effect of mAP against relative object size dimensions within images?\",\\n   \"a\": \"This paper investigates the effect of mAP against relative object size dimensions within images and shows that training the network on input images with objects adequate for its input size increases network performance on a restricted evaluation as well as when evaluating the network on the original validation dataset.\"\\n  },\\n  {\\n   \"q\": \"What is the memory footprint of the TinyissimoYOLO network?\",\\n   \"a\": \"The memory footprint of the TinyissimoYOLO network is less than 0.5 MB.\"\\n  },\\n  {\\n   \"q\": \"What is the input image size of the TinyissimoYOLO network?\",\\n   \"a\": \"The input image size of the TinyissimoYOLO network is 88x88 pixels.\"\\n  },\\n  {\\n   \"q\": \"What is the output layer size of the TinyissimoYOLO network?\",\\n   \"a\": \"The output layer size of the TinyissimoYOLO network is 4x4(2xBbox+C).\"\\n  },\\n  {\\n   \"q\": \"What is the number of convolutional layers in the TinyissimoYOLO network?\",\\n   \"a\": \"The number of convolutional layers in the TinyissimoYOLO network is 10.\"\\n  }\\n ]\\n}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "summary = json.loads(summary_json)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "epebCJTAaHgx",
        "outputId": "ed59441d-606a-4c9d-dc9d-77fd2dc8ba3a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for qas in summary['qa']:\n",
        "  print(qas['q'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "ddcUjLlyfZqx",
        "outputId": "14266387-6829-452c-ab77-2bfc44acf506"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the main contribution of this paper?\n",
            "What are the key design decisions of the TinyissimoYOLO network?\n",
            "How is the TinyissimoYOLO network trained and evaluated?\n",
            "On which microcontrollers is the TinyissimoYOLO network deployed?\n",
            "How does the MAX78000 microcontroller compare to the other microcontrollers in terms of performance?\n",
            "What is the effect of mAP against relative object size dimensions within images?\n",
            "What is the memory footprint of the TinyissimoYOLO network?\n",
            "What is the input image size of the TinyissimoYOLO network?\n",
            "What is the output layer size of the TinyissimoYOLO network?\n",
            "What is the number of convolutional layers in the TinyissimoYOLO network?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig0_desc = call_gemini(\n",
        "    prompt=f'Below is the summary of the academic paper, {summary[\"title\"]}. '\n",
        "           'Based on the summary, give me the description of the given figure. '\n",
        "           'Give me your response by filling in the following JSON. '\n",
        "           '{\"description\": text}',\n",
        "    given_text=summary['summary'],\n",
        "    given_image=figures[0],\n",
        "    API_KEY=GEMINI_API_KEY\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "NBo9-DyP-xgQ",
        "outputId": "b3d1378d-54b6-4e0d-9016-7318cf64c550"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig0_desc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "OqiOW3CcX7hT",
        "outputId": "0d6c22c4-4933-4ce6-be4a-67ebf3eddedb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' {\"description\": \"This figure shows the architecture of the proposed TinyissimoYOLO network. It consists of a stack of convolutional layers with 3x3 kernels and a fully connected layer at the output. The network is designed to have a low memory footprint and is suitable for edge processors with limited memory and computational resources.\"}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L08gV3DMbIoT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}